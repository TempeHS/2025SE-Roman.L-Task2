{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Home](../../README.md)\n",
    "\n",
    "### Feature Engineering\n",
    "\n",
    "This Jupyter Notepad includes the data engineering processes applied to my data before model training to maximise the performance of my machine learning model. We will engineer new or improved features for the bike demand data we previously wrangled.\n",
    "\n",
    "#### Feature Engineering Process\n",
    "- Deriving new variables from existing ones\n",
    "    - Encoding categorical features\n",
    "    - Calculating new features from existing features\n",
    "- Combining features/feature interactions\n",
    "- Identifying the most relevant features for the model\n",
    "- Transforming Features\n",
    "  - [Dividing Data into categories](https://web.ma.utexas.edu/users/mks/statmistakes/dividingcontinuousintocategories.html)\n",
    "  - Mathematical transformations (for example logarithmic transformations). Logarithmic transformations are a powerful tool in the world of statistical analysis. They are often used to transform data that exhibit skewness or other irregularities, making it easier to analyze, visualize, and interpret the results.\n",
    "- Creating Domain-Specific Features that incorporating knowledge from the specific domain to create features that capture important characteristics of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load the required dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import frameworks\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Store the data as a local variable\n",
    "\n",
    "The data frame is a Pandas object that structures your tabular data into an appropriate format. It loads the complete data in memory so it is now ready for preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame = pd.read_csv(\"2.2.1.wrangled_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Deriving new variables from existing ones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encoding categorical variables\n",
    "\n",
    "Data Encoding converts textual data into numerical format, so that it can be used as input for algorithms to process. The reason for encoding is that most machine learning algorithms work with numbers and not with text or categorical variables.\n",
    "\n",
    "* To encode the `Seasons` column we will assign a number value to each season\n",
    "\n",
    "    * Since the data set only provides 4 values we will use 1, 2, 3 and 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    4.0\n",
      "1    4.0\n",
      "2    4.0\n",
      "3    4.0\n",
      "4    4.0\n",
      "Name: Seasons, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data_frame['Seasons'] = data_frame['Seasons'].apply(lambda season: 1 if season.lower() == 'spring' else 2 if season.lower() == 'summer' else 3 if season.lower() == 'fall' else 4 if season.lower() == 'winter' else None)\n",
    "print(data_frame['Seasons'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We will do the same for `FunctioningDay` and `Holiday` for 2 values instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    1\n",
      "1    1\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: FunctioningDay, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_frame['FunctioningDay'] = data_frame['FunctioningDay'].apply(lambda day: 1 if day.lower() == 'yes' else 0)\n",
    "print(data_frame['FunctioningDay'].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0\n",
      "1    0\n",
      "2    0\n",
      "3    0\n",
      "4    0\n",
      "Name: Holiday, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "data_frame['Holiday'] = data_frame['Holiday'].apply(lambda holiday: 1 if holiday.lower() == 'yes' else 0)\n",
    "print(data_frame['Holiday'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Encoding categorical variables\n",
    "\n",
    "* In the context of urban transportation, time is a very important aspect to determine human behaviour\n",
    "\n",
    "    * Rush hour is inbetween the hours of 7-9 (AM) and 5-7 (PM). We will convert two dates, and further encode this into brackets\n",
    "\n",
    "    * Day of the week is also converted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date  Hour  DayOfWeek  RushHour\n",
      "2160 2018-03-01     0          3         0\n",
      "2161 2018-03-01     1          3         0\n",
      "2162 2018-03-01     2          3         0\n",
      "2163 2018-03-01     3          3         0\n",
      "2164 2018-03-01     4          3         0\n"
     ]
    }
   ],
   "source": [
    "# Convert 'Date' column to datetime\n",
    "data_frame['Date'] = pd.to_datetime(data_frame['Date'], format='%d/%m/%Y')\n",
    "\n",
    "# Create Day of the Week feature\n",
    "data_frame['DayOfWeek'] = data_frame['Date'].dt.dayofweek\n",
    "\n",
    "# Create Rush Hour feature\n",
    "data_frame['RushHour'] = data_frame['Hour'].apply(lambda x: 1 if (7 <= x <= 9) or (17 <= x <= 19) else 0)\n",
    "\n",
    "# Print the result to verify the new features\n",
    "print(data_frame[['Date', 'Hour', 'DayOfWeek', 'RushHour']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* We can also create a seperate bracket for months. giving better insight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Date  Month\n",
      "2160 2018-03-01      3\n",
      "2161 2018-03-01      3\n",
      "2162 2018-03-01      3\n",
      "2163 2018-03-01      3\n",
      "2164 2018-03-01      3\n"
     ]
    }
   ],
   "source": [
    "# Extract the month from the 'Date' column\n",
    "data_frame['Month'] = data_frame['Date'].dt.month\n",
    "\n",
    "# Print the first few rows to verify\n",
    "print(data_frame[['Date', 'Month']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Combining features/feature interactions\n",
    "\n",
    "While individual features can be powerful predictors, their interactions often carry even more information. Feature interaction engineering is the process of creating new features that represent the interaction between two or more features.\n",
    "\n",
    "* In this case, domain knowledge (urban mobility and transportation) and data analysis suggest that high dew point temperatures (indicating humidity) combined with peak riding hours can influence bike-sharing demand. Specifically, hot and humid conditions during busy times (e.g., midday or evening commutes) may lead to reduced usage due to discomfort or heat-related health risks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      DewPointTemp  Hour  HourDPT%\n",
      "2160           1.4     0      0.00\n",
      "2161           1.6     1      0.00\n",
      "2162           1.5     2      0.01\n",
      "2163           1.1     3      0.01\n",
      "2164           1.1     4      0.01\n",
      "...            ...   ...       ...\n",
      "4363           0.0    19      0.00\n",
      "4364          14.3    20      0.58\n",
      "4365          13.7    21      0.58\n",
      "4366          12.7    22      0.57\n",
      "4367          12.9    23      0.60\n",
      "\n",
      "[2208 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "data_frame['HourDPT'] = (data_frame['DewPointTemp']) * data_frame['Hour']\n",
    "\n",
    "# Calculate the percentage of the maximum risk\n",
    "data_frame['HourDPT%'] = (data_frame['HourDPT'] / data_frame['HourDPT'].max()).round(2)\n",
    "\n",
    "# Print the result\n",
    "print(data_frame[['DewPointTemp', 'Hour', 'HourDPT%']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* High dew point in the afternoon where users may avoid biking\n",
    "\n",
    "* Low dew point at night is more comfortable and has stable demand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transforming Features\n",
    "\n",
    "Filtering is like applying the where clause in a database. It is widely used and can help when you need to work on a specific subset of your data. For our use case, let us filter the data to only include rows where the `Seasons` is Summer. There is no method call for this, we can just use conditional indexing to fulfil our purpose.\n",
    "\n",
    "* In this, case some domain knowledge and data analysis have informed us that each season has a different trend.\n",
    "\n",
    "    * (Curating will also lower our sample size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Hour  Seasons     Count\n",
      "2160     0      1.0  0.029583\n",
      "2161     1      1.0  0.061250\n",
      "2162     2      1.0  0.075000\n",
      "2163     3      1.0  0.038333\n",
      "2164     4      1.0  0.011667\n",
      "...    ...      ...       ...\n",
      "4363    19      1.0  1.055833\n",
      "4364    20      1.0  0.901667\n",
      "4365    21      1.0  0.862500\n",
      "4366    22      1.0  0.791667\n",
      "4367    23      1.0  0.559583\n",
      "\n",
      "[2208 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "# Filter the data to 1 only for Summer\n",
    "data_frame = data_frame[data_frame['Seasons'] == 1]\n",
    "\n",
    "# Print the result\n",
    "print(data_frame[['Hour', 'Seasons', 'Count']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Domain-Specific Features\n",
    "\n",
    "Domain knowledge is about understanding the domain or subject area of the data. In this case, the domain is urban mobility and transportation, which involves understanding how environmental and temporal factors influence bike-sharing demand.\n",
    "\n",
    "* The column called **Comfort Index** is a domain-specific feature as it combines temperature and humidity to reflect how comfortable the weather feels for biking. Domain-specific knowledge indicates that weather comfort significantly impacts bike-sharing usage, as extreme discomfort (e.g., high humidity and temperature) can deter users. I also considered other features like:\n",
    "\n",
    "    * **Rainfall to rush hour interaction:** may impact commuting patterns\n",
    "\n",
    "    * **Rainfall to snowfall interaction:** precipitation intensity (these values were too low/low variance)\n",
    "\n",
    "* First, we will convert the Comfort Index value to a scaled percentage, because comfort can never be 0. We will scale the result between 0.15 and 0.95 to normalize the values for better interpretability and use in predictive modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw ComfortIndex Min: -1.0295999999999994\n",
      "Raw ComfortIndex Max: 24.1214\n",
      "      ComfortIndex  ComfortIndexScaled  Temp  Humidity\n",
      "2160       2.27500                0.25   2.0        96\n",
      "2161       2.30460                0.25   2.1        97\n",
      "2162       2.20625                0.25   2.0        97\n",
      "2163       1.81285                0.23   1.6        97\n",
      "2164       1.81285                0.23   1.6        97\n",
      "...            ...                 ...   ...       ...\n",
      "4363      22.43405                0.85  25.2        53\n",
      "4364      21.11340                0.81  23.1        58\n",
      "4365      20.27200                0.79  21.9        60\n",
      "4366      19.61170                0.77  21.1        59\n",
      "4367      19.24600                0.75  20.5        62\n",
      "\n",
      "[2208 rows x 4 columns]\n",
      "count    2208.000000\n",
      "mean        0.574284\n",
      "std         0.152157\n",
      "min         0.150000\n",
      "25%         0.460000\n",
      "50%         0.590000\n",
      "75%         0.690000\n",
      "max         0.900000\n",
      "Name: ComfortIndexScaled, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Create Weather Comfort Index\n",
    "data_frame['ComfortIndex'] = data_frame['Temp'] - (0.55 * (1 - (data_frame['Humidity'] / 100)) * (data_frame['Temp'] - 14.5))\n",
    "\n",
    "print(\"Raw ComfortIndex Min:\", data_frame['ComfortIndex'].min())\n",
    "print(\"Raw ComfortIndex Max:\", data_frame['ComfortIndex'].max())\n",
    "\n",
    "# Scale the ComfortIndex between 0.15 and 0.90\n",
    "min_val = 0.15\n",
    "max_val = 0.90\n",
    "data_frame['ComfortIndexScaled'] = (((data_frame['ComfortIndex'] - data_frame['ComfortIndex'].min()) / (data_frame['ComfortIndex'].max() - data_frame['ComfortIndex'].min())) * (max_val - min_val) + min_val).round(2)\n",
    "\n",
    "# Print the result\n",
    "print(data_frame[['ComfortIndex', 'ComfortIndexScaled', 'Temp', 'Humidity']])\n",
    "print(data_frame['ComfortIndexScaled'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then to make it even more meaningful, we will combine it with the `HourDPT` feature we engineered using the `Hour` and `DewPointTemp` features to create a combined comfort 'interaction feature' that captures real-world relationships between the features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Hour  HourDPT%  ComfortIndex  ComfortAdd  ComfortAddScaled\n",
      "2160     0      0.00       2.27500        0.00              0.32\n",
      "2161     1      0.00       2.30460        0.00              0.32\n",
      "2162     2      0.01       2.20625        0.02              0.32\n",
      "2163     3      0.01       1.81285        0.02              0.32\n",
      "2164     4      0.01       1.81285        0.02              0.32\n",
      "...    ...       ...           ...         ...               ...\n",
      "4363    19      0.00      22.43405        0.00              0.32\n",
      "4364    20      0.49      21.11340       10.35              0.59\n",
      "4365    21      0.49      20.27200        9.93              0.58\n",
      "4366    22      0.48      19.61170        9.41              0.56\n",
      "4367    23      0.51      19.24600        9.82              0.57\n",
      "\n",
      "[2208 rows x 5 columns]\n",
      "count    2208.000000\n",
      "mean        0.574284\n",
      "std         0.152157\n",
      "min         0.150000\n",
      "25%         0.460000\n",
      "50%         0.590000\n",
      "75%         0.690000\n",
      "max         0.900000\n",
      "Name: ComfortIndexScaled, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "data_frame['ComfortAdd'] = (data_frame['ComfortIndex'] * data_frame['HourDPT%']).round(2)\n",
    "\n",
    "min_val = 0.15\n",
    "max_val = 0.80\n",
    "data_frame['ComfortAddScaled'] = (((data_frame['ComfortAdd'] - data_frame['ComfortAdd'].min()) / (data_frame['ComfortAdd'].max() - data_frame['ComfortAdd'].min())) * (max_val - min_val) + min_val).round(2)\n",
    "\n",
    "# Print the result\n",
    "print(data_frame[['Hour', 'HourDPT%', 'ComfortIndex', 'ComfortAdd', 'ComfortAddScaled']])\n",
    "print(data_frame['ComfortIndexScaled'].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* (This feature proved ineffective later on)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of negative values in each column:\n",
      "Count                   0\n",
      "Hour                    0\n",
      "Temp                   22\n",
      "Humidity                0\n",
      "WindSpeed               0\n",
      "Visibility              0\n",
      "DewPointTemp          662\n",
      "SolarRadiation          0\n",
      "Rainfall                0\n",
      "Snowfall                0\n",
      "Seasons                 0\n",
      "Holiday                 0\n",
      "FunctioningDay          0\n",
      "DayOfWeek               0\n",
      "RushHour                0\n",
      "Month                   0\n",
      "HourDPT               637\n",
      "HourDPT%              602\n",
      "ComfortIndex            5\n",
      "ComfortIndexScaled      0\n",
      "ComfortAdd            596\n",
      "ComfortAddScaled        0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Select only numeric columns\n",
    "numeric_columns = data_frame.select_dtypes(include=['number'])\n",
    "\n",
    "# Count negative values for all numeric columns\n",
    "negative_values = (numeric_columns < 0).sum()\n",
    "\n",
    "# Print the result\n",
    "print(\"Number of negative values in each column:\")\n",
    "print(negative_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* I noticed negative values, however this is normal for Temp and DewTemp\n",
    "\n",
    "* Scaled values such as 'ComfortIndexScaled' were negative so to counteract this I created a smaller range or `max_val`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I also considered scaling some features such as `Temp`, however all features are already varied which is futile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the wrangled and engineered data to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_frame.to_csv('../2.3.model_training/2.3.1.model_ready_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
